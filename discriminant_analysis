from typing import Type
from matplotlib.markers import MarkerStyle
import numpy as np
import pandas as pd
import sklearn as sl
import matplotlib.pyplot as plt

from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

##########
def process_analysis(data, method:str='l', shuff:bool=False, plot:bool=False):
    print(data.shape)
    print(1, ": ")
    X, y = separate_discriminant(data)
    print(X.shape, y.shape)
    print()

    X_train, X_test, y_train, y_test = separate_train_test(X, y, shuff)
    print_shapes(2, X_train, X_test, y_train, y_test)

    X_train, X_test = standard_scaling(X_train, X_test)
    print_shapes(3, X_train, X_test, y_train, y_test)
    
    if method=='l':
        analyser = linear_discriminant_analyser(X_train, y_train)
        trans = dimensionality_reduction(analyser, X)
        print(trans.shape)
        if plot:
            plot_reduction(trans, y)
    elif method=='q':
        analyser = quadratic_discriminant_analyser(X_train, y_train)
    elif method=='f':
        analyser = forest_classifier(X_train, y_train)
    y_pred = analyser.predict(X_test)
    print_shapes(4, X_train, X_test, y_train, y_test)
    
    acc = evaluate_confusion_matrix(y_test, y_pred)
    print_shapes(5, X_train, X_test, y_train, y_test)
    return acc

def print_shapes(k, X_train, X_test, y_train, y_test):
    print()
    print(k, ": ")
    print('x_train:', X_train.shape, 'y_train:', y_train.shape)
    print('x_test:', X_test.shape, 'y_test:', y_test.shape)
    return

##########
def separate_discriminant(data):
    cMax = data.shape[1]
    X = data[:, 0:cMax-1]
    y = data[:, cMax-1]
    return(X, y)

def separate_train_test(X, y, shuff):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=shuff)
    return(X_train, X_test, y_train, y_test)

def standard_scaling(X_train, X_test):
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    return(X_train, X_test)

###
def quadratic_discriminant_analyser(X_train, y_train):
    qda = QDA()
    qda.fit(X_train, y_train)
    return qda

def forest_classifier(X_train, y_train):
    classifier = RandomForestClassifier(max_depth=2, random_state=0)
    classifier.fit(X_train, y_train)
    return classifier

###
def linear_discriminant_analyser(X_train, y_train):
    lda = LDA(n_components=None, store_covariance=True)
    lda.fit(X_train, y_train)
    print(lda.covariance_.shape)
    print(lda.coef_.shape)
    return lda

def dimensionality_reduction(analyser, X):
    var_ratios = analyser.explained_variance_ratio_
    trans = analyser.transform(X)
    return trans

###
def plot_reduction(trans, y):
    grave = y == 1
    lMax = trans.shape[0]
    N = np.count_nonzero(grave)
    print(trans[grave].shape)
    print(trans[~grave].shape)
    plt.close('all')
    plt.scatter(trans[grave], np.zeros(N), marker='+', color='r', label='forme grave')
    plt.scatter(trans[~grave], np.zeros(lMax-N), marker='+', color='b', label='forme légère')
    plt.legend()
    plt.show()
    return

def select_n_components(var_ratio, goal_var: float) -> int:
    total_variance = 0.0
    n_components = 0
    for explained_variance in var_ratio:
        total_variance += explained_variance
        n_components += 1
        if total_variance >= goal_var:
            break
    return n_components

###
def evaluate_confusion_matrix(y_test, y_pred):
    cm = confusion_matrix(y_test, y_pred)
    acc = accuracy_score(y_test, y_pred)
    print(cm)
    print('Accuracy: ' + str(acc))
    return acc

##########
if __name__ == "__main__":
    from load_data import database_preop
    data = database_preop().values
    l = []
    for k in range(100):
        acc = process_analysis(data, method='l', shuff=True)
        l.append(acc)
    l = np.array(l)
    print()
    print("mean: ", l.mean(0))